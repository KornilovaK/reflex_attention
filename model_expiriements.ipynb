{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gQUcrCgzxvkb"
   },
   "source": [
    "### NanoGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-TPy_Nlb5aMe"
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/karpathy/nanoGPT.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch numpy transformers datasets tiktoken wandb tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import math\n",
    "import pickle\n",
    "from contextlib import nullcontext\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.distributed import init_process_group, destroy_process_group\n",
    "\n",
    "from nanoGPT.model import GPT\n",
    "import torch._dynamo\n",
    "torch._dynamo.config.suppress_errors = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GPTConfig:\n",
    "    batch_size: int = 32\n",
    "    block_size: int = 1024\n",
    "    vocab_size: int = 50304\n",
    "    n_layer: int = 6\n",
    "    n_head: int = 8\n",
    "    n_embd: int = 768\n",
    "    dropout: float = 0.1\n",
    "    bias: bool = False\n",
    "    model_type: str = 'reflex'\n",
    "    \n",
    "config = GPTConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_log = True\n",
    "wandb_project = 'research-task'\n",
    "is_True = 'True' if config.bias else 'False'\n",
    "wandb_run_name = f'all_layer-{config.model_type}-{config.block_size}-{is_True}-{config.n_embd}-{config.dropout}'\n",
    "\n",
    "out_dir = 'mini-gpt'\n",
    "eval_interval = 250\n",
    "eval_iters = 200\n",
    "log_interval = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_accumulation_steps = 1\n",
    "\n",
    "learning_rate = 1e-3\n",
    "max_iters = 10000\n",
    "lr_decay_iters = 5000\n",
    "min_lr = 1e-5\n",
    "warmup_iters = 400\n",
    "\n",
    "eval_only = False \n",
    "always_save_checkpoint = False\n",
    "\n",
    "weight_decay = 1e-1\n",
    "decay_lr = True\n",
    "beta1 = 0.9\n",
    "beta2 = 0.98\n",
    "grad_clip = 1.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens per iteration will be: 32,768\n"
     ]
    }
   ],
   "source": [
    "# DDP settings\n",
    "backend = 'nccl' # 'nccl', 'gloo', etc.\n",
    "# system\n",
    "device = 'cuda' # examples: 'cpu', 'cuda', 'cuda:0', 'cuda:1' etc., or try 'mps' on macbooks\n",
    "dtype = 'bfloat16' if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else 'float16' # 'float32', 'bfloat16', or 'float16', the latter will auto implement a GradScaler\n",
    "compile = True # use PyTorch 2.0 to compile the model to be faster\n",
    "\n",
    "# various inits, derived attributes, I/O setup\n",
    "ddp = int(os.environ.get('RANK', -1)) != -1 # is this a ddp run?\n",
    "if ddp:\n",
    "    init_process_group(backend=backend)\n",
    "    ddp_rank = int(os.environ['RANK'])\n",
    "    ddp_local_rank = int(os.environ['LOCAL_RANK'])\n",
    "    ddp_world_size = int(os.environ['WORLD_SIZE'])\n",
    "    device = f'cuda:{ddp_local_rank}'\n",
    "    torch.cuda.set_device(device)\n",
    "    master_process = ddp_rank == 0 # this process will do logging, checkpointing etc.\n",
    "    seed_offset = ddp_rank # each process gets a different seed\n",
    "    # world_size number of processes will be training simultaneously, so we can scale\n",
    "    # down the desired gradient accumulation iterations per process proportionally\n",
    "    assert gradient_accumulation_steps % ddp_world_size == 0\n",
    "    gradient_accumulation_steps //= ddp_world_size\n",
    "else:\n",
    "    # if not ddp, we are running on a single gpu, and one process\n",
    "    master_process = True\n",
    "    seed_offset = 0\n",
    "    ddp_world_size = 1\n",
    "tokens_per_iter = gradient_accumulation_steps * ddp_world_size * config.batch_size * config.block_size\n",
    "print(f\"tokens per iteration will be: {tokens_per_iter:,}\")\n",
    "\n",
    "if master_process:\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "torch.manual_seed(1337 + seed_offset)\n",
    "torch.backends.cuda.matmul.allow_tf32 = True # allow tf32 on matmul\n",
    "torch.backends.cudnn.allow_tf32 = True # allow tf32 on cudnn\n",
    "device_type = 'cuda' if 'cuda' in device else 'cpu' # for later use in torch.autocast\n",
    "# note: float16 data type will automatically use a GradScaler\n",
    "ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]\n",
    "ctx = nullcontext() if device_type == 'cpu' else torch.amp.autocast(device_type=device_type, dtype=ptdtype)\n",
    "\n",
    "data_dir = 'nanoGPT/data/openwebtext'\n",
    "def get_batch(split):\n",
    "    batch_size = config.batch_size\n",
    "    block_size = config.block_size\n",
    "    # We recreate np.memmap every batch to avoid a memory leak, as per\n",
    "    # https://stackoverflow.com/questions/45132940/numpy-memmap-memory-usage-want-to-iterate-once/61472122#61472122\n",
    "    if split == 'train':\n",
    "        data = np.memmap(os.path.join(data_dir, 'train.bin'), dtype=np.uint16, mode='r')\n",
    "    else:\n",
    "        data = np.memmap(os.path.join(data_dir, 'val.bin'), dtype=np.uint16, mode='r')\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([torch.from_numpy((data[i:i+block_size]).astype(np.int64)) for i in ix])\n",
    "    y = torch.stack([torch.from_numpy((data[i+1:i+1+block_size]).astype(np.int64)) for i in ix])\n",
    "    if device_type == 'cuda':\n",
    "        # pin arrays x,y, which allows us to move them to GPU asynchronously (non_blocking=True)\n",
    "        x, y = x.pin_memory().to(device, non_blocking=True), y.pin_memory().to(device, non_blocking=True)\n",
    "    else:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "iter_num = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing a new model from scratch\n",
      "number of parameters: 81.11M\n"
     ]
    }
   ],
   "source": [
    "# model init\n",
    "model_args = dict(n_layer=config.n_layer, n_head=config.n_head, n_embd=config.n_embd, block_size=config.block_size,\n",
    "                  bias=config.bias, vocab_size=config.vocab_size, dropout=config.dropout)\n",
    "\n",
    "# init a new model from scratch\n",
    "print(\"Initializing a new model from scratch\")\n",
    "model = GPT(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "# initialize a GradScaler. If enabled=False scaler is a no-op\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num decayed parameter tensors: 26, with 81,887,232 parameters\n",
      "num non-decayed parameter tensors: 13, with 9,984 parameters\n",
      "using fused AdamW: True\n",
      "compiling the model... (takes a ~minute)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkornilova_eka\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/user/wandb/run-20241117_185943-ypp54xwn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kornilova_eka/research-task/runs/ypp54xwn' target=\"_blank\">all_layer-reflex-1024-False-768-0.1</a></strong> to <a href='https://wandb.ai/kornilova_eka/research-task' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kornilova_eka/research-task' target=\"_blank\">https://wandb.ai/kornilova_eka/research-task</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kornilova_eka/research-task/runs/ypp54xwn' target=\"_blank\">https://wandb.ai/kornilova_eka/research-task/runs/ypp54xwn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer = model.configure_optimizers(weight_decay, learning_rate, (beta1, beta2), device_type)\n",
    "checkpoint = None # free up memory\n",
    "\n",
    "# compile the model\n",
    "if compile:\n",
    "    print(\"compiling the model... (takes a ~minute)\")\n",
    "    unoptimized_model = model\n",
    "    model = torch.compile(model) # requires PyTorch 2.0\n",
    "\n",
    "# wrap model into DDP container\n",
    "if ddp:\n",
    "    model = DDP(model, device_ids=[ddp_local_rank])\n",
    "\n",
    "# helps estimate an arbitrarily accurate loss over either split using many batches\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            with ctx:\n",
    "                logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "# learning rate decay scheduler (cosine with warmup)\n",
    "def get_lr(it):\n",
    "    # 1) linear warmup for warmup_iters steps\n",
    "    if it < warmup_iters:\n",
    "        return learning_rate * it / warmup_iters\n",
    "    # 2) if it > lr_decay_iters, return min learning rate\n",
    "    if it > lr_decay_iters:\n",
    "        return min_lr\n",
    "    # 3) in between, use cosine decay down to min learning rate\n",
    "    decay_ratio = (it - warmup_iters) / (lr_decay_iters - warmup_iters)\n",
    "    assert 0 <= decay_ratio <= 1\n",
    "    coeff = 0.5 * (1.0 + math.cos(math.pi * decay_ratio)) # coeff ranges 0..1\n",
    "    return min_lr + coeff * (learning_rate - min_lr)\n",
    "\n",
    "# logging\n",
    "if wandb_log and master_process:\n",
    "    import wandb\n",
    "    wandb.init(project=wandb_project, name=wandb_run_name, config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824] WON'T CONVERT forward /home/user/nanoGPT/model.py line 146 \n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824] due to: \n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824] Traceback (most recent call last):\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 786, in _convert_frame\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     result = inner_convert(\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 400, in _convert_frame_assert\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     return _compile(\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     return func(*args, **kwds)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 676, in _compile\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 535, in compile_inner\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     out_code = transform_code_object(code, transform)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/bytecode_transformation.py\", line 1036, in transform_code_object\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     transformations(instructions, code_options)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 165, in _fn\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     return fn(*args, **kwargs)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 500, in transform\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     tracer.run()\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2149, in run\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     super().run()\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/symbolic_convert.py\", line 810, in run\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     and self.step()\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/symbolic_convert.py\", line 773, in step\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     getattr(self, inst.opname)(inst)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2268, in RETURN_VALUE\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     self.output.compile_subgraph(\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/output_graph.py\", line 1001, in compile_subgraph\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     self.compile_and_call_fx_graph(tx, pass2.graph_output_vars(), root)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     return func(*args, **kwds)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/output_graph.py\", line 1178, in compile_and_call_fx_graph\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fn = self.call_user_compiler(gm)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/output_graph.py\", line 1251, in call_user_compiler\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/output_graph.py\", line 1232, in call_user_compiler\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/repro/after_dynamo.py\", line 117, in debug_wrapper\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/__init__.py\", line 1731, in __call__\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     return func(*args, **kwds)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/compile_fx.py\", line 1330, in compile_fx\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     return aot_autograd(\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/backends/common.py\", line 58, in compiler_fn\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     cg = aot_module_simplified(gm, example_inputs, **kwargs)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_functorch/aot_autograd.py\", line 903, in aot_module_simplified\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fn = create_aot_dispatcher_function(\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_functorch/aot_autograd.py\", line 628, in create_aot_dispatcher_function\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py\", line 443, in aot_wrapper_dedupe\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py\", line 648, in aot_wrapper_synthetic_base\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 119, in aot_dispatch_base\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fw = compiler(fw_module, updated_flat_args)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/compile_fx.py\", line 1257, in fw_compiler_base\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     return inner_compile(\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/repro/after_aot.py\", line 83, in debug_wrapper\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/debug.py\", line 304, in inner\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     return fn(*args, **kwargs)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     return func(*args, **kwds)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     return func(*args, **kwds)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/compile_fx.py\", line 438, in compile_fx_inner\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_graph = fx_codegen_and_compile(\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/compile_fx.py\", line 714, in fx_codegen_and_compile\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fn = graph.compile_to_fn()\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/graph.py\", line 1307, in compile_to_fn\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     return self.compile_to_module().call\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/graph.py\", line 1250, in compile_to_module\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/graph.py\", line 1208, in codegen\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     self.scheduler.codegen()\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/scheduler.py\", line 2339, in codegen\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     self.get_backend(device).codegen_nodes(node.get_nodes())  # type: ignore[possibly-undefined]\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/codegen/cuda_combined_scheduling.py\", line 63, in codegen_nodes\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     return self._triton_scheduling.codegen_nodes(nodes)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/codegen/triton.py\", line 3255, in codegen_nodes\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     return self.codegen_node_schedule(node_schedule, buf_accesses, numel, rnumel)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/codegen/triton.py\", line 3425, in codegen_node_schedule\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     src_code = kernel.codegen_kernel()\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/codegen/triton.py\", line 2753, in codegen_kernel\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     \"backend_hash\": torch.utils._triton.triton_hash_with_backend(),\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/utils/_triton.py\", line 102, in triton_hash_with_backend\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     key = f\"{triton_key()}-{backend_hash}\"\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/utils/_triton.py\", line 76, in triton_key\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     with open(os.path.join(TRITON_PATH, \"_C/libtriton.so\"), \"rb\") as f:\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824] FileNotFoundError: [Errno 2] No such file or directory: '/usr/lib/python3/dist-packages/triton/_C/libtriton.so'\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824] \n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824] \n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824] Traceback (most recent call last):\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 786, in _convert_frame\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     result = inner_convert(\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 400, in _convert_frame_assert\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     return _compile(\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     return func(*args, **kwds)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 676, in _compile\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 535, in compile_inner\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     out_code = transform_code_object(code, transform)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/bytecode_transformation.py\", line 1036, in transform_code_object\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     transformations(instructions, code_options)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 165, in _fn\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     return fn(*args, **kwargs)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 500, in transform\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     tracer.run()\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2149, in run\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     super().run()\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/symbolic_convert.py\", line 810, in run\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     and self.step()\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/symbolic_convert.py\", line 773, in step\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     getattr(self, inst.opname)(inst)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2268, in RETURN_VALUE\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     self.output.compile_subgraph(\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/output_graph.py\", line 1001, in compile_subgraph\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     self.compile_and_call_fx_graph(tx, pass2.graph_output_vars(), root)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     return func(*args, **kwds)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/output_graph.py\", line 1178, in compile_and_call_fx_graph\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fn = self.call_user_compiler(gm)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/output_graph.py\", line 1251, in call_user_compiler\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/output_graph.py\", line 1232, in call_user_compiler\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/repro/after_dynamo.py\", line 117, in debug_wrapper\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/__init__.py\", line 1731, in __call__\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     return func(*args, **kwds)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/compile_fx.py\", line 1330, in compile_fx\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     return aot_autograd(\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/backends/common.py\", line 58, in compiler_fn\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     cg = aot_module_simplified(gm, example_inputs, **kwargs)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_functorch/aot_autograd.py\", line 903, in aot_module_simplified\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fn = create_aot_dispatcher_function(\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_functorch/aot_autograd.py\", line 628, in create_aot_dispatcher_function\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py\", line 443, in aot_wrapper_dedupe\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py\", line 648, in aot_wrapper_synthetic_base\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 119, in aot_dispatch_base\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fw = compiler(fw_module, updated_flat_args)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/compile_fx.py\", line 1257, in fw_compiler_base\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     return inner_compile(\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/repro/after_aot.py\", line 83, in debug_wrapper\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/debug.py\", line 304, in inner\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     return fn(*args, **kwargs)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     return func(*args, **kwds)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     return func(*args, **kwds)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/compile_fx.py\", line 438, in compile_fx_inner\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_graph = fx_codegen_and_compile(\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/compile_fx.py\", line 714, in fx_codegen_and_compile\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fn = graph.compile_to_fn()\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/graph.py\", line 1307, in compile_to_fn\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     return self.compile_to_module().call\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/graph.py\", line 1250, in compile_to_module\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/graph.py\", line 1208, in codegen\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     self.scheduler.codegen()\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/scheduler.py\", line 2339, in codegen\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     self.get_backend(device).codegen_nodes(node.get_nodes())  # type: ignore[possibly-undefined]\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/codegen/cuda_combined_scheduling.py\", line 63, in codegen_nodes\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     return self._triton_scheduling.codegen_nodes(nodes)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/codegen/triton.py\", line 3255, in codegen_nodes\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     return self.codegen_node_schedule(node_schedule, buf_accesses, numel, rnumel)\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/codegen/triton.py\", line 3425, in codegen_node_schedule\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     src_code = kernel.codegen_kernel()\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/codegen/triton.py\", line 2753, in codegen_kernel\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     \"backend_hash\": torch.utils._triton.triton_hash_with_backend(),\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/utils/_triton.py\", line 102, in triton_hash_with_backend\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     key = f\"{triton_key()}-{backend_hash}\"\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/utils/_triton.py\", line 76, in triton_key\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824]     with open(os.path.join(TRITON_PATH, \"_C/libtriton.so\"), \"rb\") as f:\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824] FileNotFoundError: [Errno 2] No such file or directory: '/usr/lib/python3/dist-packages/triton/_C/libtriton.so'\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824] \n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W1117 18:59:49.947000 140390391898112 torch/_dynamo/convert_frame.py:824] \n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824] WON'T CONVERT forward /home/user/nanoGPT/model.py line 93 \n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824] due to: \n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824] Traceback (most recent call last):\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 786, in _convert_frame\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     result = inner_convert(\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 400, in _convert_frame_assert\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     return _compile(\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     return func(*args, **kwds)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 676, in _compile\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 535, in compile_inner\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     out_code = transform_code_object(code, transform)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/bytecode_transformation.py\", line 1036, in transform_code_object\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     transformations(instructions, code_options)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 165, in _fn\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     return fn(*args, **kwargs)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 500, in transform\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     tracer.run()\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2149, in run\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     super().run()\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/symbolic_convert.py\", line 810, in run\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     and self.step()\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/symbolic_convert.py\", line 773, in step\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     getattr(self, inst.opname)(inst)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2268, in RETURN_VALUE\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     self.output.compile_subgraph(\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/output_graph.py\", line 1001, in compile_subgraph\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     self.compile_and_call_fx_graph(tx, pass2.graph_output_vars(), root)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     return func(*args, **kwds)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/output_graph.py\", line 1178, in compile_and_call_fx_graph\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fn = self.call_user_compiler(gm)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/output_graph.py\", line 1251, in call_user_compiler\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/output_graph.py\", line 1232, in call_user_compiler\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/repro/after_dynamo.py\", line 117, in debug_wrapper\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/__init__.py\", line 1731, in __call__\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     return func(*args, **kwds)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/compile_fx.py\", line 1330, in compile_fx\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     return aot_autograd(\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/backends/common.py\", line 58, in compiler_fn\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     cg = aot_module_simplified(gm, example_inputs, **kwargs)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_functorch/aot_autograd.py\", line 903, in aot_module_simplified\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fn = create_aot_dispatcher_function(\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_functorch/aot_autograd.py\", line 628, in create_aot_dispatcher_function\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py\", line 443, in aot_wrapper_dedupe\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py\", line 648, in aot_wrapper_synthetic_base\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 119, in aot_dispatch_base\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fw = compiler(fw_module, updated_flat_args)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/compile_fx.py\", line 1257, in fw_compiler_base\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     return inner_compile(\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/repro/after_aot.py\", line 83, in debug_wrapper\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/debug.py\", line 304, in inner\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     return fn(*args, **kwargs)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     return func(*args, **kwds)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     return func(*args, **kwds)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/compile_fx.py\", line 438, in compile_fx_inner\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_graph = fx_codegen_and_compile(\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/compile_fx.py\", line 714, in fx_codegen_and_compile\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fn = graph.compile_to_fn()\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/graph.py\", line 1307, in compile_to_fn\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     return self.compile_to_module().call\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/graph.py\", line 1250, in compile_to_module\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/graph.py\", line 1208, in codegen\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     self.scheduler.codegen()\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/scheduler.py\", line 2339, in codegen\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     self.get_backend(device).codegen_nodes(node.get_nodes())  # type: ignore[possibly-undefined]\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/codegen/cuda_combined_scheduling.py\", line 63, in codegen_nodes\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     return self._triton_scheduling.codegen_nodes(nodes)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/codegen/triton.py\", line 3255, in codegen_nodes\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     return self.codegen_node_schedule(node_schedule, buf_accesses, numel, rnumel)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/codegen/triton.py\", line 3425, in codegen_node_schedule\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     src_code = kernel.codegen_kernel()\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/codegen/triton.py\", line 2753, in codegen_kernel\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     \"backend_hash\": torch.utils._triton.triton_hash_with_backend(),\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/utils/_triton.py\", line 102, in triton_hash_with_backend\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     key = f\"{triton_key()}-{backend_hash}\"\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/utils/_triton.py\", line 76, in triton_key\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     with open(os.path.join(TRITON_PATH, \"_C/libtriton.so\"), \"rb\") as f:\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824] FileNotFoundError: [Errno 2] No such file or directory: '/usr/lib/python3/dist-packages/triton/_C/libtriton.so'\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824] \n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824] \n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824] Traceback (most recent call last):\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 786, in _convert_frame\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     result = inner_convert(\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 400, in _convert_frame_assert\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     return _compile(\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     return func(*args, **kwds)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 676, in _compile\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 535, in compile_inner\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     out_code = transform_code_object(code, transform)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/bytecode_transformation.py\", line 1036, in transform_code_object\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     transformations(instructions, code_options)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 165, in _fn\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     return fn(*args, **kwargs)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 500, in transform\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     tracer.run()\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2149, in run\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     super().run()\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/symbolic_convert.py\", line 810, in run\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     and self.step()\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/symbolic_convert.py\", line 773, in step\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     getattr(self, inst.opname)(inst)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2268, in RETURN_VALUE\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     self.output.compile_subgraph(\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/output_graph.py\", line 1001, in compile_subgraph\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     self.compile_and_call_fx_graph(tx, pass2.graph_output_vars(), root)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     return func(*args, **kwds)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/output_graph.py\", line 1178, in compile_and_call_fx_graph\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fn = self.call_user_compiler(gm)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/output_graph.py\", line 1251, in call_user_compiler\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/output_graph.py\", line 1232, in call_user_compiler\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/repro/after_dynamo.py\", line 117, in debug_wrapper\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/__init__.py\", line 1731, in __call__\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     return func(*args, **kwds)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/compile_fx.py\", line 1330, in compile_fx\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     return aot_autograd(\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/backends/common.py\", line 58, in compiler_fn\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     cg = aot_module_simplified(gm, example_inputs, **kwargs)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_functorch/aot_autograd.py\", line 903, in aot_module_simplified\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fn = create_aot_dispatcher_function(\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_functorch/aot_autograd.py\", line 628, in create_aot_dispatcher_function\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py\", line 443, in aot_wrapper_dedupe\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py\", line 648, in aot_wrapper_synthetic_base\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 119, in aot_dispatch_base\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fw = compiler(fw_module, updated_flat_args)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/compile_fx.py\", line 1257, in fw_compiler_base\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     return inner_compile(\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/repro/after_aot.py\", line 83, in debug_wrapper\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/debug.py\", line 304, in inner\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     return fn(*args, **kwargs)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     return func(*args, **kwds)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     return func(*args, **kwds)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/compile_fx.py\", line 438, in compile_fx_inner\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_graph = fx_codegen_and_compile(\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/compile_fx.py\", line 714, in fx_codegen_and_compile\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fn = graph.compile_to_fn()\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/graph.py\", line 1307, in compile_to_fn\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     return self.compile_to_module().call\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/graph.py\", line 1250, in compile_to_module\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/graph.py\", line 1208, in codegen\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     self.scheduler.codegen()\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/scheduler.py\", line 2339, in codegen\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     self.get_backend(device).codegen_nodes(node.get_nodes())  # type: ignore[possibly-undefined]\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/codegen/cuda_combined_scheduling.py\", line 63, in codegen_nodes\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     return self._triton_scheduling.codegen_nodes(nodes)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/codegen/triton.py\", line 3255, in codegen_nodes\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     return self.codegen_node_schedule(node_schedule, buf_accesses, numel, rnumel)\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/codegen/triton.py\", line 3425, in codegen_node_schedule\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     src_code = kernel.codegen_kernel()\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/codegen/triton.py\", line 2753, in codegen_kernel\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     \"backend_hash\": torch.utils._triton.triton_hash_with_backend(),\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/utils/_triton.py\", line 102, in triton_hash_with_backend\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     key = f\"{triton_key()}-{backend_hash}\"\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/utils/_triton.py\", line 76, in triton_key\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824]     with open(os.path.join(TRITON_PATH, \"_C/libtriton.so\"), \"rb\") as f:\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824] FileNotFoundError: [Errno 2] No such file or directory: '/usr/lib/python3/dist-packages/triton/_C/libtriton.so'\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824] \n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W1117 18:59:50.445000 140390391898112 torch/_dynamo/convert_frame.py:824] \n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824] WON'T CONVERT forward /home/user/nanoGPT/model.py line 17 \n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824] due to: \n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824] Traceback (most recent call last):\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 786, in _convert_frame\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     result = inner_convert(\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 400, in _convert_frame_assert\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     return _compile(\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     return func(*args, **kwds)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 676, in _compile\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 535, in compile_inner\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     out_code = transform_code_object(code, transform)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/bytecode_transformation.py\", line 1036, in transform_code_object\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     transformations(instructions, code_options)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 165, in _fn\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     return fn(*args, **kwargs)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 500, in transform\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     tracer.run()\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2149, in run\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     super().run()\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/symbolic_convert.py\", line 810, in run\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     and self.step()\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/symbolic_convert.py\", line 773, in step\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     getattr(self, inst.opname)(inst)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2268, in RETURN_VALUE\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     self.output.compile_subgraph(\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/output_graph.py\", line 981, in compile_subgraph\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     return func(*args, **kwds)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/output_graph.py\", line 1178, in compile_and_call_fx_graph\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fn = self.call_user_compiler(gm)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/output_graph.py\", line 1251, in call_user_compiler\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/output_graph.py\", line 1232, in call_user_compiler\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/repro/after_dynamo.py\", line 117, in debug_wrapper\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/__init__.py\", line 1731, in __call__\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     return func(*args, **kwds)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/compile_fx.py\", line 1330, in compile_fx\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     return aot_autograd(\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/backends/common.py\", line 58, in compiler_fn\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     cg = aot_module_simplified(gm, example_inputs, **kwargs)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_functorch/aot_autograd.py\", line 903, in aot_module_simplified\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fn = create_aot_dispatcher_function(\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_functorch/aot_autograd.py\", line 628, in create_aot_dispatcher_function\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py\", line 443, in aot_wrapper_dedupe\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py\", line 648, in aot_wrapper_synthetic_base\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 119, in aot_dispatch_base\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fw = compiler(fw_module, updated_flat_args)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/compile_fx.py\", line 1257, in fw_compiler_base\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     return inner_compile(\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/repro/after_aot.py\", line 83, in debug_wrapper\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/debug.py\", line 304, in inner\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     return fn(*args, **kwargs)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     return func(*args, **kwds)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     return func(*args, **kwds)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/compile_fx.py\", line 438, in compile_fx_inner\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_graph = fx_codegen_and_compile(\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/compile_fx.py\", line 714, in fx_codegen_and_compile\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fn = graph.compile_to_fn()\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/graph.py\", line 1307, in compile_to_fn\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     return self.compile_to_module().call\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/graph.py\", line 1250, in compile_to_module\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/graph.py\", line 1208, in codegen\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     self.scheduler.codegen()\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/scheduler.py\", line 2339, in codegen\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     self.get_backend(device).codegen_nodes(node.get_nodes())  # type: ignore[possibly-undefined]\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/codegen/cuda_combined_scheduling.py\", line 63, in codegen_nodes\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     return self._triton_scheduling.codegen_nodes(nodes)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/codegen/triton.py\", line 3255, in codegen_nodes\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     return self.codegen_node_schedule(node_schedule, buf_accesses, numel, rnumel)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/codegen/triton.py\", line 3425, in codegen_node_schedule\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     src_code = kernel.codegen_kernel()\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/codegen/triton.py\", line 2753, in codegen_kernel\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     \"backend_hash\": torch.utils._triton.triton_hash_with_backend(),\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/utils/_triton.py\", line 102, in triton_hash_with_backend\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     key = f\"{triton_key()}-{backend_hash}\"\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/utils/_triton.py\", line 76, in triton_key\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     with open(os.path.join(TRITON_PATH, \"_C/libtriton.so\"), \"rb\") as f:\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824] FileNotFoundError: [Errno 2] No such file or directory: '/usr/lib/python3/dist-packages/triton/_C/libtriton.so'\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824] \n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824] \n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824] Traceback (most recent call last):\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 786, in _convert_frame\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     result = inner_convert(\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 400, in _convert_frame_assert\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     return _compile(\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     return func(*args, **kwds)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 676, in _compile\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 535, in compile_inner\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     out_code = transform_code_object(code, transform)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/bytecode_transformation.py\", line 1036, in transform_code_object\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     transformations(instructions, code_options)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 165, in _fn\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     return fn(*args, **kwargs)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 500, in transform\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     tracer.run()\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2149, in run\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     super().run()\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/symbolic_convert.py\", line 810, in run\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     and self.step()\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/symbolic_convert.py\", line 773, in step\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     getattr(self, inst.opname)(inst)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2268, in RETURN_VALUE\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     self.output.compile_subgraph(\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/output_graph.py\", line 981, in compile_subgraph\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     return func(*args, **kwds)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/output_graph.py\", line 1178, in compile_and_call_fx_graph\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fn = self.call_user_compiler(gm)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/output_graph.py\", line 1251, in call_user_compiler\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/output_graph.py\", line 1232, in call_user_compiler\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/repro/after_dynamo.py\", line 117, in debug_wrapper\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/__init__.py\", line 1731, in __call__\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     return func(*args, **kwds)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/compile_fx.py\", line 1330, in compile_fx\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     return aot_autograd(\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/backends/common.py\", line 58, in compiler_fn\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     cg = aot_module_simplified(gm, example_inputs, **kwargs)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_functorch/aot_autograd.py\", line 903, in aot_module_simplified\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fn = create_aot_dispatcher_function(\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_functorch/aot_autograd.py\", line 628, in create_aot_dispatcher_function\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py\", line 443, in aot_wrapper_dedupe\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py\", line 648, in aot_wrapper_synthetic_base\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 119, in aot_dispatch_base\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fw = compiler(fw_module, updated_flat_args)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/compile_fx.py\", line 1257, in fw_compiler_base\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     return inner_compile(\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/repro/after_aot.py\", line 83, in debug_wrapper\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/debug.py\", line 304, in inner\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     return fn(*args, **kwargs)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     return func(*args, **kwds)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     return func(*args, **kwds)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/compile_fx.py\", line 438, in compile_fx_inner\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_graph = fx_codegen_and_compile(\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/compile_fx.py\", line 714, in fx_codegen_and_compile\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fn = graph.compile_to_fn()\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/graph.py\", line 1307, in compile_to_fn\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     return self.compile_to_module().call\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/graph.py\", line 1250, in compile_to_module\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/graph.py\", line 1208, in codegen\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     self.scheduler.codegen()\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/scheduler.py\", line 2339, in codegen\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     self.get_backend(device).codegen_nodes(node.get_nodes())  # type: ignore[possibly-undefined]\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/codegen/cuda_combined_scheduling.py\", line 63, in codegen_nodes\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     return self._triton_scheduling.codegen_nodes(nodes)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/codegen/triton.py\", line 3255, in codegen_nodes\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     return self.codegen_node_schedule(node_schedule, buf_accesses, numel, rnumel)\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/codegen/triton.py\", line 3425, in codegen_node_schedule\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     src_code = kernel.codegen_kernel()\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/codegen/triton.py\", line 2753, in codegen_kernel\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     \"backend_hash\": torch.utils._triton.triton_hash_with_backend(),\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/utils/_triton.py\", line 102, in triton_hash_with_backend\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     key = f\"{triton_key()}-{backend_hash}\"\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/utils/_triton.py\", line 76, in triton_key\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824]     with open(os.path.join(TRITON_PATH, \"_C/libtriton.so\"), \"rb\") as f:\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824] FileNotFoundError: [Errno 2] No such file or directory: '/usr/lib/python3/dist-packages/triton/_C/libtriton.so'\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824] \n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W1117 18:59:50.528000 140390391898112 torch/_dynamo/convert_frame.py:824] \n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824] WON'T CONVERT forward /home/user/nanoGPT/model.py line 34 \n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824] due to: \n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824] Traceback (most recent call last):\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 786, in _convert_frame\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     result = inner_convert(\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 400, in _convert_frame_assert\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     return _compile(\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     return func(*args, **kwds)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 676, in _compile\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 535, in compile_inner\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     out_code = transform_code_object(code, transform)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/bytecode_transformation.py\", line 1036, in transform_code_object\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     transformations(instructions, code_options)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 165, in _fn\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     return fn(*args, **kwargs)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 500, in transform\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     tracer.run()\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2149, in run\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     super().run()\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/symbolic_convert.py\", line 810, in run\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     and self.step()\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/symbolic_convert.py\", line 773, in step\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     getattr(self, inst.opname)(inst)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2268, in RETURN_VALUE\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     self.output.compile_subgraph(\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/output_graph.py\", line 1001, in compile_subgraph\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     self.compile_and_call_fx_graph(tx, pass2.graph_output_vars(), root)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     return func(*args, **kwds)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/output_graph.py\", line 1178, in compile_and_call_fx_graph\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fn = self.call_user_compiler(gm)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/output_graph.py\", line 1251, in call_user_compiler\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/output_graph.py\", line 1232, in call_user_compiler\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/repro/after_dynamo.py\", line 117, in debug_wrapper\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/__init__.py\", line 1731, in __call__\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     return func(*args, **kwds)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/compile_fx.py\", line 1330, in compile_fx\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     return aot_autograd(\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/backends/common.py\", line 58, in compiler_fn\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     cg = aot_module_simplified(gm, example_inputs, **kwargs)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_functorch/aot_autograd.py\", line 903, in aot_module_simplified\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fn = create_aot_dispatcher_function(\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_functorch/aot_autograd.py\", line 628, in create_aot_dispatcher_function\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py\", line 443, in aot_wrapper_dedupe\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py\", line 648, in aot_wrapper_synthetic_base\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 119, in aot_dispatch_base\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fw = compiler(fw_module, updated_flat_args)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/compile_fx.py\", line 1257, in fw_compiler_base\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     return inner_compile(\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/repro/after_aot.py\", line 83, in debug_wrapper\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/debug.py\", line 304, in inner\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     return fn(*args, **kwargs)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     return func(*args, **kwds)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     return func(*args, **kwds)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/compile_fx.py\", line 438, in compile_fx_inner\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_graph = fx_codegen_and_compile(\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/compile_fx.py\", line 714, in fx_codegen_and_compile\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fn = graph.compile_to_fn()\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/graph.py\", line 1307, in compile_to_fn\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     return self.compile_to_module().call\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/graph.py\", line 1250, in compile_to_module\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/graph.py\", line 1208, in codegen\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     self.scheduler.codegen()\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/scheduler.py\", line 2339, in codegen\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     self.get_backend(device).codegen_nodes(node.get_nodes())  # type: ignore[possibly-undefined]\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/codegen/cuda_combined_scheduling.py\", line 63, in codegen_nodes\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     return self._triton_scheduling.codegen_nodes(nodes)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/codegen/triton.py\", line 3255, in codegen_nodes\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     return self.codegen_node_schedule(node_schedule, buf_accesses, numel, rnumel)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/codegen/triton.py\", line 3425, in codegen_node_schedule\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     src_code = kernel.codegen_kernel()\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/codegen/triton.py\", line 2753, in codegen_kernel\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     \"backend_hash\": torch.utils._triton.triton_hash_with_backend(),\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/utils/_triton.py\", line 102, in triton_hash_with_backend\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     key = f\"{triton_key()}-{backend_hash}\"\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/utils/_triton.py\", line 76, in triton_key\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     with open(os.path.join(TRITON_PATH, \"_C/libtriton.so\"), \"rb\") as f:\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824] FileNotFoundError: [Errno 2] No such file or directory: '/usr/lib/python3/dist-packages/triton/_C/libtriton.so'\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824] \n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824] \n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824] Traceback (most recent call last):\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 786, in _convert_frame\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     result = inner_convert(\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 400, in _convert_frame_assert\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     return _compile(\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     return func(*args, **kwds)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 676, in _compile\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 535, in compile_inner\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     out_code = transform_code_object(code, transform)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/bytecode_transformation.py\", line 1036, in transform_code_object\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     transformations(instructions, code_options)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 165, in _fn\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     return fn(*args, **kwargs)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 500, in transform\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     tracer.run()\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2149, in run\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     super().run()\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/symbolic_convert.py\", line 810, in run\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     and self.step()\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/symbolic_convert.py\", line 773, in step\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     getattr(self, inst.opname)(inst)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2268, in RETURN_VALUE\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     self.output.compile_subgraph(\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/output_graph.py\", line 1001, in compile_subgraph\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     self.compile_and_call_fx_graph(tx, pass2.graph_output_vars(), root)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     return func(*args, **kwds)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/output_graph.py\", line 1178, in compile_and_call_fx_graph\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fn = self.call_user_compiler(gm)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/output_graph.py\", line 1251, in call_user_compiler\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/output_graph.py\", line 1232, in call_user_compiler\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/repro/after_dynamo.py\", line 117, in debug_wrapper\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/__init__.py\", line 1731, in __call__\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     return func(*args, **kwds)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/compile_fx.py\", line 1330, in compile_fx\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     return aot_autograd(\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/backends/common.py\", line 58, in compiler_fn\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     cg = aot_module_simplified(gm, example_inputs, **kwargs)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_functorch/aot_autograd.py\", line 903, in aot_module_simplified\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fn = create_aot_dispatcher_function(\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_functorch/aot_autograd.py\", line 628, in create_aot_dispatcher_function\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py\", line 443, in aot_wrapper_dedupe\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py\", line 648, in aot_wrapper_synthetic_base\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 119, in aot_dispatch_base\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fw = compiler(fw_module, updated_flat_args)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/compile_fx.py\", line 1257, in fw_compiler_base\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     return inner_compile(\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/repro/after_aot.py\", line 83, in debug_wrapper\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/debug.py\", line 304, in inner\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     return fn(*args, **kwargs)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     return func(*args, **kwds)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     return func(*args, **kwds)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/compile_fx.py\", line 438, in compile_fx_inner\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_graph = fx_codegen_and_compile(\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/compile_fx.py\", line 714, in fx_codegen_and_compile\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fn = graph.compile_to_fn()\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/graph.py\", line 1307, in compile_to_fn\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     return self.compile_to_module().call\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/graph.py\", line 1250, in compile_to_module\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/graph.py\", line 1208, in codegen\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     self.scheduler.codegen()\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/scheduler.py\", line 2339, in codegen\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     self.get_backend(device).codegen_nodes(node.get_nodes())  # type: ignore[possibly-undefined]\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/codegen/cuda_combined_scheduling.py\", line 63, in codegen_nodes\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     return self._triton_scheduling.codegen_nodes(nodes)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/codegen/triton.py\", line 3255, in codegen_nodes\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     return self.codegen_node_schedule(node_schedule, buf_accesses, numel, rnumel)\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/codegen/triton.py\", line 3425, in codegen_node_schedule\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     src_code = kernel.codegen_kernel()\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/codegen/triton.py\", line 2753, in codegen_kernel\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     \"backend_hash\": torch.utils._triton.triton_hash_with_backend(),\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/utils/_triton.py\", line 102, in triton_hash_with_backend\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     key = f\"{triton_key()}-{backend_hash}\"\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/utils/_triton.py\", line 76, in triton_key\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824]     with open(os.path.join(TRITON_PATH, \"_C/libtriton.so\"), \"rb\") as f:\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824] FileNotFoundError: [Errno 2] No such file or directory: '/usr/lib/python3/dist-packages/triton/_C/libtriton.so'\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824] \n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W1117 18:59:50.716000 140390391898112 torch/_dynamo/convert_frame.py:824] \n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824] WON'T CONVERT forward /home/user/nanoGPT/model.py line 77 \n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824] due to: \n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824] Traceback (most recent call last):\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 786, in _convert_frame\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     result = inner_convert(\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 400, in _convert_frame_assert\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     return _compile(\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     return func(*args, **kwds)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 676, in _compile\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 535, in compile_inner\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     out_code = transform_code_object(code, transform)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/bytecode_transformation.py\", line 1036, in transform_code_object\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     transformations(instructions, code_options)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 165, in _fn\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     return fn(*args, **kwargs)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 500, in transform\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     tracer.run()\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2149, in run\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     super().run()\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/symbolic_convert.py\", line 810, in run\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     and self.step()\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/symbolic_convert.py\", line 773, in step\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     getattr(self, inst.opname)(inst)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2268, in RETURN_VALUE\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     self.output.compile_subgraph(\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/output_graph.py\", line 981, in compile_subgraph\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     return func(*args, **kwds)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/output_graph.py\", line 1178, in compile_and_call_fx_graph\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fn = self.call_user_compiler(gm)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/output_graph.py\", line 1251, in call_user_compiler\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/output_graph.py\", line 1232, in call_user_compiler\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/repro/after_dynamo.py\", line 117, in debug_wrapper\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/__init__.py\", line 1731, in __call__\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     return func(*args, **kwds)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/compile_fx.py\", line 1330, in compile_fx\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     return aot_autograd(\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/backends/common.py\", line 58, in compiler_fn\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     cg = aot_module_simplified(gm, example_inputs, **kwargs)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_functorch/aot_autograd.py\", line 903, in aot_module_simplified\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fn = create_aot_dispatcher_function(\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_functorch/aot_autograd.py\", line 628, in create_aot_dispatcher_function\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py\", line 443, in aot_wrapper_dedupe\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py\", line 648, in aot_wrapper_synthetic_base\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 119, in aot_dispatch_base\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fw = compiler(fw_module, updated_flat_args)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/compile_fx.py\", line 1257, in fw_compiler_base\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     return inner_compile(\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/repro/after_aot.py\", line 83, in debug_wrapper\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/debug.py\", line 304, in inner\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     return fn(*args, **kwargs)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     return func(*args, **kwds)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     return func(*args, **kwds)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/compile_fx.py\", line 438, in compile_fx_inner\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_graph = fx_codegen_and_compile(\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/compile_fx.py\", line 714, in fx_codegen_and_compile\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fn = graph.compile_to_fn()\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/graph.py\", line 1307, in compile_to_fn\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     return self.compile_to_module().call\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/graph.py\", line 1250, in compile_to_module\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/graph.py\", line 1208, in codegen\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     self.scheduler.codegen()\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/scheduler.py\", line 2339, in codegen\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     self.get_backend(device).codegen_nodes(node.get_nodes())  # type: ignore[possibly-undefined]\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/codegen/cuda_combined_scheduling.py\", line 63, in codegen_nodes\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     return self._triton_scheduling.codegen_nodes(nodes)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/codegen/triton.py\", line 3255, in codegen_nodes\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     return self.codegen_node_schedule(node_schedule, buf_accesses, numel, rnumel)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/codegen/triton.py\", line 3425, in codegen_node_schedule\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     src_code = kernel.codegen_kernel()\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/codegen/triton.py\", line 2753, in codegen_kernel\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     \"backend_hash\": torch.utils._triton.triton_hash_with_backend(),\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/utils/_triton.py\", line 102, in triton_hash_with_backend\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     key = f\"{triton_key()}-{backend_hash}\"\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/utils/_triton.py\", line 76, in triton_key\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     with open(os.path.join(TRITON_PATH, \"_C/libtriton.so\"), \"rb\") as f:\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824] FileNotFoundError: [Errno 2] No such file or directory: '/usr/lib/python3/dist-packages/triton/_C/libtriton.so'\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824] \n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824] \n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824] Traceback (most recent call last):\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 786, in _convert_frame\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     result = inner_convert(\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 400, in _convert_frame_assert\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     return _compile(\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     return func(*args, **kwds)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 676, in _compile\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 535, in compile_inner\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     out_code = transform_code_object(code, transform)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/bytecode_transformation.py\", line 1036, in transform_code_object\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     transformations(instructions, code_options)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 165, in _fn\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     return fn(*args, **kwargs)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/convert_frame.py\", line 500, in transform\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     tracer.run()\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2149, in run\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     super().run()\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/symbolic_convert.py\", line 810, in run\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     and self.step()\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/symbolic_convert.py\", line 773, in step\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     getattr(self, inst.opname)(inst)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2268, in RETURN_VALUE\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     self.output.compile_subgraph(\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/output_graph.py\", line 981, in compile_subgraph\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     return func(*args, **kwds)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/output_graph.py\", line 1178, in compile_and_call_fx_graph\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fn = self.call_user_compiler(gm)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/output_graph.py\", line 1251, in call_user_compiler\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/output_graph.py\", line 1232, in call_user_compiler\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/repro/after_dynamo.py\", line 117, in debug_wrapper\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/__init__.py\", line 1731, in __call__\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     return func(*args, **kwds)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/compile_fx.py\", line 1330, in compile_fx\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     return aot_autograd(\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/backends/common.py\", line 58, in compiler_fn\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     cg = aot_module_simplified(gm, example_inputs, **kwargs)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_functorch/aot_autograd.py\", line 903, in aot_module_simplified\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fn = create_aot_dispatcher_function(\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_functorch/aot_autograd.py\", line 628, in create_aot_dispatcher_function\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py\", line 443, in aot_wrapper_dedupe\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py\", line 648, in aot_wrapper_synthetic_base\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 119, in aot_dispatch_base\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fw = compiler(fw_module, updated_flat_args)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/compile_fx.py\", line 1257, in fw_compiler_base\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     return inner_compile(\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/repro/after_aot.py\", line 83, in debug_wrapper\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/debug.py\", line 304, in inner\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     return fn(*args, **kwargs)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     return func(*args, **kwds)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     return func(*args, **kwds)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/compile_fx.py\", line 438, in compile_fx_inner\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_graph = fx_codegen_and_compile(\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/compile_fx.py\", line 714, in fx_codegen_and_compile\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     compiled_fn = graph.compile_to_fn()\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/graph.py\", line 1307, in compile_to_fn\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     return self.compile_to_module().call\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/graph.py\", line 1250, in compile_to_module\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/graph.py\", line 1208, in codegen\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     self.scheduler.codegen()\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_dynamo/utils.py\", line 262, in time_wrapper\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     r = func(*args, **kwargs)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/scheduler.py\", line 2339, in codegen\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     self.get_backend(device).codegen_nodes(node.get_nodes())  # type: ignore[possibly-undefined]\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/codegen/cuda_combined_scheduling.py\", line 63, in codegen_nodes\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     return self._triton_scheduling.codegen_nodes(nodes)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/codegen/triton.py\", line 3255, in codegen_nodes\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     return self.codegen_node_schedule(node_schedule, buf_accesses, numel, rnumel)\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/codegen/triton.py\", line 3425, in codegen_node_schedule\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     src_code = kernel.codegen_kernel()\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/_inductor/codegen/triton.py\", line 2753, in codegen_kernel\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     \"backend_hash\": torch.utils._triton.triton_hash_with_backend(),\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/utils/_triton.py\", line 102, in triton_hash_with_backend\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     key = f\"{triton_key()}-{backend_hash}\"\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]   File \"/usr/lib/python3/dist-packages/torch/utils/_triton.py\", line 76, in triton_key\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824]     with open(os.path.join(TRITON_PATH, \"_C/libtriton.so\"), \"rb\") as f:\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824] FileNotFoundError: [Errno 2] No such file or directory: '/usr/lib/python3/dist-packages/triton/_C/libtriton.so'\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824] \n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W1117 18:59:50.943000 140390391898112 torch/_dynamo/convert_frame.py:824] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 10.9429, val loss 10.9425\n",
      "iter 0: loss 10.9527, time 31559.07ms, mfu -100.00%\n",
      "iter 10: loss 9.7819, time 189.10ms, mfu 30.17%\n",
      "iter 20: loss 9.3407, time 189.00ms, mfu 30.18%\n",
      "iter 30: loss 8.7671, time 188.42ms, mfu 30.19%\n",
      "iter 40: loss 8.0848, time 187.40ms, mfu 30.21%\n",
      "iter 50: loss 7.4833, time 187.09ms, mfu 30.24%\n",
      "iter 60: loss 7.1131, time 187.76ms, mfu 30.26%\n",
      "iter 70: loss 7.2629, time 187.56ms, mfu 30.27%\n",
      "iter 80: loss 6.8479, time 188.15ms, mfu 30.28%\n",
      "iter 90: loss 6.9234, time 188.47ms, mfu 30.28%\n",
      "iter 100: loss 6.7939, time 188.71ms, mfu 30.27%\n",
      "iter 110: loss 6.7392, time 189.02ms, mfu 30.26%\n",
      "iter 120: loss 6.3867, time 188.07ms, mfu 30.27%\n",
      "iter 130: loss 6.5128, time 190.27ms, mfu 30.24%\n",
      "iter 140: loss 6.4810, time 188.53ms, mfu 30.25%\n",
      "iter 150: loss 6.3648, time 189.16ms, mfu 30.24%\n",
      "iter 160: loss 6.3628, time 189.06ms, mfu 30.23%\n",
      "iter 170: loss 6.3086, time 189.60ms, mfu 30.22%\n",
      "iter 180: loss 6.2953, time 188.44ms, mfu 30.22%\n",
      "iter 190: loss 6.1896, time 190.08ms, mfu 30.20%\n",
      "iter 200: loss 6.2460, time 188.44ms, mfu 30.21%\n",
      "iter 210: loss 6.4164, time 189.84ms, mfu 30.20%\n",
      "iter 220: loss 6.3459, time 189.74ms, mfu 30.18%\n",
      "iter 230: loss 6.1148, time 189.65ms, mfu 30.17%\n",
      "iter 240: loss 6.1335, time 189.93ms, mfu 30.16%\n",
      "step 250: train loss 6.1161, val loss 6.1266\n",
      "saving checkpoint to mini-gpt\n",
      "iter 250: loss 6.0728, time 28914.52ms, mfu 27.16%\n",
      "iter 260: loss 6.1279, time 190.26ms, mfu 27.45%\n",
      "iter 270: loss 6.1001, time 188.84ms, mfu 27.72%\n",
      "iter 280: loss 6.0363, time 190.32ms, mfu 27.95%\n",
      "iter 290: loss 6.0962, time 189.12ms, mfu 28.17%\n",
      "iter 300: loss 5.9632, time 192.44ms, mfu 28.32%\n",
      "iter 310: loss 6.0327, time 189.53ms, mfu 28.50%\n",
      "iter 320: loss 6.0260, time 189.26ms, mfu 28.66%\n",
      "iter 330: loss 6.1827, time 190.02ms, mfu 28.80%\n",
      "iter 340: loss 5.9764, time 189.08ms, mfu 28.94%\n",
      "iter 350: loss 5.9655, time 189.69ms, mfu 29.05%\n",
      "iter 360: loss 5.9287, time 191.77ms, mfu 29.12%\n",
      "iter 370: loss 5.8912, time 189.01ms, mfu 29.23%\n",
      "iter 380: loss 5.7997, time 189.94ms, mfu 29.31%\n",
      "iter 390: loss 5.8209, time 190.23ms, mfu 29.38%\n",
      "iter 400: loss 5.9845, time 189.59ms, mfu 29.45%\n",
      "iter 410: loss 5.9359, time 191.27ms, mfu 29.49%\n",
      "iter 420: loss 5.8884, time 189.66ms, mfu 29.55%\n",
      "iter 430: loss 5.9496, time 189.58ms, mfu 29.60%\n",
      "iter 440: loss 5.8915, time 189.40ms, mfu 29.66%\n",
      "iter 450: loss 5.8330, time 190.02ms, mfu 29.69%\n",
      "iter 460: loss 5.8964, time 189.82ms, mfu 29.73%\n",
      "iter 470: loss 5.6893, time 189.69ms, mfu 29.76%\n",
      "iter 480: loss 5.6268, time 189.94ms, mfu 29.79%\n",
      "iter 490: loss 5.7455, time 190.03ms, mfu 29.82%\n",
      "step 500: train loss 5.7147, val loss 5.7171\n",
      "saving checkpoint to mini-gpt\n",
      "iter 500: loss 5.7623, time 29128.56ms, mfu 26.85%\n",
      "iter 510: loss 5.6937, time 190.40ms, mfu 27.16%\n",
      "iter 520: loss 5.7126, time 188.48ms, mfu 27.48%\n",
      "iter 530: loss 5.6202, time 189.27ms, mfu 27.74%\n",
      "iter 540: loss 5.6342, time 190.11ms, mfu 27.97%\n",
      "iter 550: loss 5.6725, time 190.71ms, mfu 28.16%\n",
      "iter 560: loss 5.5979, time 189.66ms, mfu 28.36%\n",
      "iter 570: loss 5.7144, time 190.93ms, mfu 28.51%\n",
      "iter 580: loss 5.5719, time 190.53ms, mfu 28.65%\n",
      "iter 590: loss 5.5661, time 189.02ms, mfu 28.81%\n",
      "iter 600: loss 5.6214, time 189.48ms, mfu 28.94%\n",
      "iter 610: loss 5.5273, time 189.86ms, mfu 29.05%\n",
      "iter 620: loss 5.4656, time 189.38ms, mfu 29.16%\n",
      "iter 630: loss 5.5759, time 190.69ms, mfu 29.23%\n",
      "iter 640: loss 5.5025, time 189.66ms, mfu 29.32%\n",
      "iter 650: loss 5.5273, time 189.41ms, mfu 29.40%\n",
      "iter 660: loss 5.5778, time 189.74ms, mfu 29.47%\n",
      "iter 670: loss 5.5081, time 190.92ms, mfu 29.51%\n",
      "iter 680: loss 5.5364, time 189.95ms, mfu 29.56%\n",
      "iter 690: loss 5.3345, time 190.18ms, mfu 29.61%\n",
      "iter 700: loss 5.4188, time 190.12ms, mfu 29.65%\n",
      "iter 710: loss 5.5090, time 190.70ms, mfu 29.67%\n",
      "iter 720: loss 5.3995, time 189.60ms, mfu 29.72%\n",
      "iter 730: loss 5.3253, time 190.06ms, mfu 29.75%\n",
      "iter 740: loss 5.3955, time 189.73ms, mfu 29.78%\n",
      "step 750: train loss 5.3404, val loss 5.3495\n",
      "saving checkpoint to mini-gpt\n",
      "iter 750: loss 5.5003, time 28994.20ms, mfu 26.82%\n",
      "iter 760: loss 5.4654, time 189.86ms, mfu 27.14%\n",
      "iter 770: loss 5.3044, time 189.08ms, mfu 27.45%\n",
      "iter 780: loss 5.4544, time 189.08ms, mfu 27.72%\n",
      "iter 790: loss 5.3135, time 191.03ms, mfu 27.94%\n",
      "iter 800: loss 5.1991, time 189.11ms, mfu 28.16%\n",
      "iter 810: loss 5.3251, time 190.67ms, mfu 28.34%\n",
      "iter 820: loss 5.3251, time 190.07ms, mfu 28.50%\n",
      "iter 830: loss 5.3107, time 189.35ms, mfu 28.67%\n",
      "iter 840: loss 5.3481, time 189.72ms, mfu 28.81%\n",
      "iter 850: loss 5.2548, time 189.23ms, mfu 28.94%\n",
      "iter 860: loss 5.2525, time 190.20ms, mfu 29.05%\n",
      "iter 870: loss 5.3602, time 189.30ms, mfu 29.16%\n",
      "iter 880: loss 5.2753, time 190.92ms, mfu 29.23%\n",
      "iter 890: loss 5.3710, time 190.64ms, mfu 29.30%\n",
      "iter 900: loss 5.3483, time 191.18ms, mfu 29.35%\n",
      "iter 910: loss 5.2215, time 190.77ms, mfu 29.41%\n",
      "iter 920: loss 5.1604, time 189.81ms, mfu 29.48%\n",
      "iter 930: loss 5.1289, time 189.56ms, mfu 29.54%\n",
      "iter 940: loss 5.1901, time 189.49ms, mfu 29.60%\n",
      "iter 950: loss 5.2033, time 191.10ms, mfu 29.62%\n",
      "iter 960: loss 5.1487, time 190.77ms, mfu 29.65%\n",
      "iter 970: loss 5.1678, time 190.50ms, mfu 29.68%\n",
      "iter 980: loss 5.2714, time 189.22ms, mfu 29.73%\n",
      "iter 990: loss 5.1257, time 189.67ms, mfu 29.76%\n",
      "step 1000: train loss 5.1046, val loss 5.1042\n",
      "saving checkpoint to mini-gpt\n",
      "iter 1000: loss 5.0974, time 28957.11ms, mfu 26.81%\n",
      "iter 1010: loss 5.2225, time 190.25ms, mfu 27.13%\n",
      "iter 1020: loss 5.2361, time 189.21ms, mfu 27.43%\n",
      "iter 1030: loss 5.2364, time 189.90ms, mfu 27.69%\n",
      "iter 1040: loss 5.1267, time 190.30ms, mfu 27.92%\n",
      "iter 1050: loss 5.1076, time 190.40ms, mfu 28.12%\n",
      "iter 1060: loss 5.0737, time 189.65ms, mfu 28.32%\n",
      "iter 1070: loss 5.1260, time 189.24ms, mfu 28.50%\n",
      "iter 1080: loss 5.1713, time 189.54ms, mfu 28.66%\n",
      "iter 1090: loss 5.2155, time 189.77ms, mfu 28.80%\n",
      "iter 1100: loss 5.0393, time 189.74ms, mfu 28.93%\n",
      "iter 1110: loss 5.1274, time 189.62ms, mfu 29.05%\n",
      "iter 1120: loss 5.0498, time 190.50ms, mfu 29.14%\n",
      "iter 1130: loss 4.9357, time 190.91ms, mfu 29.21%\n",
      "iter 1140: loss 5.0300, time 191.29ms, mfu 29.27%\n",
      "iter 1150: loss 4.9337, time 189.92ms, mfu 29.35%\n",
      "iter 1160: loss 5.2188, time 189.51ms, mfu 29.43%\n",
      "iter 1170: loss 5.0428, time 189.84ms, mfu 29.49%\n",
      "iter 1180: loss 4.9848, time 190.06ms, mfu 29.54%\n",
      "iter 1190: loss 4.9666, time 190.12ms, mfu 29.59%\n",
      "iter 1200: loss 4.9977, time 188.67ms, mfu 29.66%\n",
      "iter 1210: loss 4.9935, time 189.33ms, mfu 29.70%\n",
      "iter 1220: loss 4.9855, time 189.69ms, mfu 29.74%\n",
      "iter 1230: loss 4.9570, time 190.80ms, mfu 29.76%\n",
      "iter 1240: loss 5.0596, time 190.52ms, mfu 29.78%\n",
      "step 1250: train loss 4.8901, val loss 4.8952\n",
      "saving checkpoint to mini-gpt\n",
      "iter 1250: loss 4.8588, time 29002.13ms, mfu 26.82%\n",
      "iter 1260: loss 4.9674, time 191.00ms, mfu 27.12%\n",
      "iter 1270: loss 5.0345, time 190.01ms, mfu 27.41%\n",
      "iter 1280: loss 5.0779, time 189.81ms, mfu 27.68%\n",
      "iter 1290: loss 4.9376, time 189.17ms, mfu 27.93%\n",
      "iter 1300: loss 4.8756, time 188.87ms, mfu 28.16%\n",
      "iter 1310: loss 4.9781, time 189.50ms, mfu 28.35%\n",
      "iter 1320: loss 4.9622, time 189.98ms, mfu 28.52%\n",
      "iter 1330: loss 4.7970, time 189.99ms, mfu 28.67%\n",
      "iter 1340: loss 4.8812, time 189.90ms, mfu 28.81%\n",
      "iter 1350: loss 5.1373, time 191.53ms, mfu 28.91%\n",
      "iter 1360: loss 4.9435, time 190.62ms, mfu 29.01%\n",
      "iter 1370: loss 4.7090, time 191.35ms, mfu 29.09%\n",
      "iter 1380: loss 4.8967, time 190.64ms, mfu 29.17%\n",
      "iter 1390: loss 4.9592, time 189.60ms, mfu 29.27%\n",
      "iter 1400: loss 4.9065, time 189.74ms, mfu 29.35%\n",
      "iter 1410: loss 4.8851, time 189.82ms, mfu 29.42%\n",
      "iter 1420: loss 4.7834, time 190.24ms, mfu 29.48%\n",
      "iter 1430: loss 4.8085, time 191.00ms, mfu 29.52%\n",
      "iter 1440: loss 4.7827, time 189.40ms, mfu 29.58%\n",
      "iter 1450: loss 4.9302, time 190.15ms, mfu 29.62%\n",
      "iter 1460: loss 4.9343, time 189.33ms, mfu 29.67%\n",
      "iter 1470: loss 4.7566, time 189.99ms, mfu 29.71%\n",
      "iter 1480: loss 4.7818, time 190.17ms, mfu 29.74%\n",
      "iter 1490: loss 4.7948, time 190.35ms, mfu 29.76%\n",
      "step 1500: train loss 4.7189, val loss 4.7198\n",
      "saving checkpoint to mini-gpt\n",
      "iter 1500: loss 4.8750, time 29115.55ms, mfu 26.80%\n",
      "iter 1510: loss 4.8875, time 189.82ms, mfu 27.13%\n",
      "iter 1520: loss 4.9508, time 189.39ms, mfu 27.43%\n",
      "iter 1530: loss 4.6038, time 189.39ms, mfu 27.70%\n",
      "iter 1540: loss 4.7908, time 189.52ms, mfu 27.94%\n",
      "iter 1550: loss 4.6435, time 189.60ms, mfu 28.16%\n",
      "iter 1560: loss 4.7415, time 189.47ms, mfu 28.35%\n",
      "iter 1570: loss 4.6557, time 190.58ms, mfu 28.51%\n",
      "iter 1580: loss 4.7744, time 191.08ms, mfu 28.65%\n",
      "iter 1590: loss 4.7570, time 190.94ms, mfu 28.77%\n",
      "iter 1600: loss 4.7799, time 190.83ms, mfu 28.88%\n",
      "iter 1610: loss 4.7326, time 190.80ms, mfu 28.98%\n",
      "iter 1620: loss 4.7048, time 189.79ms, mfu 29.09%\n",
      "iter 1630: loss 4.7297, time 190.30ms, mfu 29.18%\n",
      "iter 1640: loss 4.7951, time 189.25ms, mfu 29.28%\n",
      "iter 1650: loss 4.6443, time 189.97ms, mfu 29.35%\n",
      "iter 1660: loss 4.7720, time 189.72ms, mfu 29.43%\n",
      "iter 1670: loss 4.5812, time 189.71ms, mfu 29.49%\n",
      "iter 1680: loss 4.6747, time 189.46ms, mfu 29.55%\n",
      "iter 1690: loss 4.6287, time 189.00ms, mfu 29.62%\n",
      "iter 1700: loss 4.6848, time 188.98ms, mfu 29.68%\n",
      "iter 1710: loss 4.5908, time 189.02ms, mfu 29.73%\n",
      "iter 1720: loss 4.6283, time 190.87ms, mfu 29.74%\n",
      "iter 1730: loss 4.6103, time 188.58ms, mfu 29.79%\n",
      "iter 1740: loss 4.7737, time 190.05ms, mfu 29.82%\n",
      "step 1750: train loss 4.5699, val loss 4.5680\n",
      "saving checkpoint to mini-gpt\n",
      "iter 1750: loss 4.6508, time 29001.12ms, mfu 26.86%\n",
      "iter 1760: loss 4.7090, time 190.93ms, mfu 27.16%\n",
      "iter 1770: loss 4.5917, time 189.02ms, mfu 27.46%\n",
      "iter 1780: loss 4.6598, time 192.51ms, mfu 27.68%\n",
      "iter 1790: loss 4.6710, time 189.85ms, mfu 27.92%\n",
      "iter 1800: loss 4.6045, time 189.12ms, mfu 28.14%\n",
      "iter 1810: loss 4.5638, time 189.14ms, mfu 28.34%\n",
      "iter 1820: loss 4.7182, time 189.16ms, mfu 28.53%\n",
      "iter 1830: loss 4.6259, time 189.01ms, mfu 28.69%\n",
      "iter 1840: loss 4.5539, time 189.50ms, mfu 28.83%\n",
      "iter 1850: loss 4.7347, time 190.09ms, mfu 28.95%\n",
      "iter 1860: loss 4.5059, time 189.67ms, mfu 29.07%\n",
      "iter 1870: loss 4.5701, time 190.19ms, mfu 29.16%\n",
      "iter 1880: loss 4.5038, time 189.65ms, mfu 29.25%\n",
      "iter 1890: loss 4.5334, time 189.65ms, mfu 29.34%\n",
      "iter 1900: loss 4.5874, time 189.16ms, mfu 29.42%\n",
      "iter 1910: loss 4.6055, time 189.18ms, mfu 29.49%\n",
      "iter 1920: loss 4.5169, time 190.01ms, mfu 29.55%\n",
      "iter 1930: loss 4.5507, time 190.51ms, mfu 29.59%\n",
      "iter 1940: loss 4.5946, time 191.03ms, mfu 29.61%\n",
      "iter 1950: loss 4.5919, time 190.92ms, mfu 29.64%\n",
      "iter 1960: loss 4.5483, time 188.39ms, mfu 29.71%\n",
      "iter 1970: loss 4.5457, time 190.66ms, mfu 29.73%\n",
      "iter 1980: loss 4.5528, time 189.58ms, mfu 29.77%\n",
      "iter 1990: loss 4.5907, time 189.77ms, mfu 29.80%\n",
      "step 2000: train loss 4.4877, val loss 4.4750\n",
      "saving checkpoint to mini-gpt\n",
      "iter 2000: loss 4.6002, time 28938.58ms, mfu 26.84%\n",
      "iter 2010: loss 4.5057, time 190.53ms, mfu 27.15%\n",
      "iter 2020: loss 4.4985, time 190.70ms, mfu 27.42%\n",
      "iter 2030: loss 4.5141, time 189.25ms, mfu 27.70%\n",
      "iter 2040: loss 4.5348, time 189.24ms, mfu 27.94%\n",
      "iter 2050: loss 4.5029, time 189.97ms, mfu 28.15%\n",
      "iter 2060: loss 4.5624, time 189.62ms, mfu 28.35%\n",
      "iter 2070: loss 4.5917, time 190.76ms, mfu 28.50%\n",
      "iter 2080: loss 4.7621, time 190.59ms, mfu 28.65%\n",
      "iter 2090: loss 4.5561, time 191.31ms, mfu 28.76%\n",
      "iter 2100: loss 4.5195, time 190.04ms, mfu 28.89%\n",
      "iter 2110: loss 4.5696, time 190.95ms, mfu 28.99%\n",
      "iter 2120: loss 4.5223, time 190.17ms, mfu 29.09%\n",
      "iter 2130: loss 4.5558, time 189.37ms, mfu 29.19%\n",
      "iter 2140: loss 4.5990, time 189.78ms, mfu 29.28%\n",
      "iter 2150: loss 4.5269, time 190.31ms, mfu 29.35%\n",
      "iter 2160: loss 4.5925, time 190.23ms, mfu 29.42%\n",
      "iter 2170: loss 4.4869, time 189.95ms, mfu 29.48%\n",
      "iter 2180: loss 4.4490, time 189.04ms, mfu 29.55%\n",
      "iter 2190: loss 4.4988, time 188.54ms, mfu 29.62%\n",
      "iter 2200: loss 4.4978, time 191.78ms, mfu 29.63%\n",
      "iter 2210: loss 4.5826, time 191.29ms, mfu 29.65%\n",
      "iter 2220: loss 4.3763, time 189.27ms, mfu 29.70%\n",
      "iter 2230: loss 4.3604, time 189.48ms, mfu 29.74%\n",
      "iter 2240: loss 4.5593, time 190.39ms, mfu 29.77%\n",
      "step 2250: train loss 4.4098, val loss 4.4126\n",
      "saving checkpoint to mini-gpt\n",
      "iter 2250: loss 4.5435, time 28987.99ms, mfu 26.81%\n",
      "iter 2260: loss 4.4615, time 188.83ms, mfu 27.15%\n",
      "iter 2270: loss 4.6741, time 190.14ms, mfu 27.44%\n",
      "iter 2280: loss 4.4755, time 189.91ms, mfu 27.70%\n",
      "iter 2290: loss 4.5606, time 190.02ms, mfu 27.93%\n",
      "iter 2300: loss 4.6198, time 189.00ms, mfu 28.16%\n",
      "iter 2310: loss 4.4457, time 190.68ms, mfu 28.33%\n",
      "iter 2320: loss 4.4183, time 189.20ms, mfu 28.52%\n",
      "iter 2330: loss 4.3763, time 189.99ms, mfu 28.67%\n",
      "iter 2340: loss 4.4580, time 190.90ms, mfu 28.79%\n",
      "iter 2350: loss 4.5605, time 189.93ms, mfu 28.91%\n",
      "iter 2360: loss 4.4683, time 189.37ms, mfu 29.04%\n",
      "iter 2370: loss 4.5139, time 190.07ms, mfu 29.13%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6730/2746903934.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_backward_grad_sync\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmicro_step\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mgradient_accumulation_steps\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mgradient_accumulation_steps\u001b[0m \u001b[0;31m# scale the loss to account for gradient accumulation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m# immediately async prefetch next batch while model is doing the forward pass on the GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/_dynamo/eval_frame.py\u001b[0m in \u001b[0;36m_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0mprior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset_eval_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 \u001b[0mset_eval_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/nanoGPT/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, idx, targets)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0;31m# if we are given some desired targets also calculate the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "iter_num = 0\n",
    "best_val_loss = 1e9\n",
    "X, Y = get_batch('train') # fetch the very first batch\n",
    "t0 = time.time()\n",
    "local_iter_num = 0 # number of iterations in the lifetime of this process\n",
    "raw_model = model.module if ddp else model # unwrap DDP container if needed\n",
    "running_mfu = -1.0\n",
    "while True:\n",
    "\n",
    "    # determine and set the learning rate for this iteration\n",
    "    lr = get_lr(iter_num) if decay_lr else learning_rate\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "    # evaluate the loss on train/val sets and write checkpoints\n",
    "    if iter_num % eval_interval == 0 and master_process:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter_num}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "        if wandb_log:\n",
    "            wandb.log({\n",
    "                \"iter\": iter_num,\n",
    "                \"train/loss\": losses['train'],\n",
    "                \"val/loss\": losses['val'],\n",
    "                \"lr\": lr,\n",
    "                \"mfu\": running_mfu*100, # convert to percentage\n",
    "            })\n",
    "        if losses['val'] < best_val_loss or always_save_checkpoint:\n",
    "            best_val_loss = losses['val']\n",
    "            if iter_num > 0:\n",
    "                checkpoint = {\n",
    "                    'model': raw_model.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'model_args': model_args,\n",
    "                    'iter_num': iter_num,\n",
    "                    'best_val_loss': best_val_loss,\n",
    "                    'config': config,\n",
    "                }\n",
    "                print(f\"saving checkpoint to {out_dir}\")\n",
    "                torch.save(checkpoint, os.path.join(out_dir, 'ckpt.pt'))\n",
    "    if iter_num == 0 and eval_only:\n",
    "        break\n",
    "\n",
    "    # forward backward update, with optional gradient accumulation to simulate larger batch size\n",
    "    # and using the GradScaler if data type is float16\n",
    "    for micro_step in range(gradient_accumulation_steps):\n",
    "        if ddp:\n",
    "            # in DDP training we only need to sync gradients at the last micro step.\n",
    "            # the official way to do this is with model.no_sync() context manager, but\n",
    "            # I really dislike that this bloats the code and forces us to repeat code\n",
    "            # looking at the source of that context manager, it just toggles this variable\n",
    "            model.require_backward_grad_sync = (micro_step == gradient_accumulation_steps - 1)\n",
    "        with ctx:\n",
    "            logits, loss = model(X, Y)\n",
    "            loss = loss / gradient_accumulation_steps # scale the loss to account for gradient accumulation\n",
    "        # immediately async prefetch next batch while model is doing the forward pass on the GPU\n",
    "        X, Y = get_batch('train')\n",
    "        # backward pass, with gradient scaling if training in fp16\n",
    "        scaler.scale(loss).backward()\n",
    "    # clip the gradient\n",
    "    if grad_clip != 0.0:\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "    # step the optimizer and scaler if training in fp16\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "    # flush the gradients as soon as we can, no need for this memory anymore\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "    # timing and logging\n",
    "    t1 = time.time()\n",
    "    dt = t1 - t0\n",
    "    t0 = t1\n",
    "    if iter_num % log_interval == 0 and master_process:\n",
    "        lossf = loss.item() * gradient_accumulation_steps\n",
    "        if local_iter_num >= 5: # let the training loop settle a bit\n",
    "            mfu = raw_model.estimate_mfu(config.batch_size * gradient_accumulation_steps, dt)\n",
    "            running_mfu = mfu if running_mfu == -1.0 else 0.9*running_mfu + 0.1*mfu\n",
    "        print(f\"iter {iter_num}: loss {lossf:.4f}, time {dt*1000:.2f}ms, mfu {running_mfu*100:.2f}%\")\n",
    "    iter_num += 1\n",
    "    local_iter_num += 1\n",
    "\n",
    "    # termination conditions\n",
    "    if iter_num > max_iters:\n",
    "        break\n",
    "\n",
    "if ddp:\n",
    "    destroy_process_group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8_lc8S9tBhZa"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "gQUcrCgzxvkb",
    "YmpQfAoX6O5E"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
