{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7ccf25ab-2abe-4480-9b5f-3f838894fe8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from contextlib import nullcontext\n",
    "import torch\n",
    "import tiktoken\n",
    "from nanoGPT.model import GPT\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61116957",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "32183522-47a5-4842-a53f-4bdb76b6d42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = 'mini-gpt-5-2-1' # ignored if init_from is not 'resume'\n",
    "start = \"How to meet a love of your life?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7800ac16-c9dd-4ea2-87e6-4fa4f518806d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 5 # number of samples to draw\n",
    "max_new_tokens = 500 # number of tokens generated in each sample\n",
    "temperature = 0.8 # 1.0 = no change, < 1.0 = less random, > 1.0 = more random, in predictions\n",
    "top_k = 100 # retain only the top_k most likely tokens, clamp others to have 0 probability\n",
    "seed = 1337\n",
    "device = 'cuda' # examples: 'cpu', 'cuda', 'cuda:0', 'cuda:1', etc.\n",
    "dtype = 'bfloat16' if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else 'float16' # 'float32' or 'bfloat16' or 'float16'\n",
    "compile = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aced7362-0623-4d6c-8bed-f070ff90a322",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GPTConfig:\n",
    "    batch_size: int = 32\n",
    "    block_size: int = 1024\n",
    "    vocab_size: int = 50304\n",
    "    n_layer: int = 6\n",
    "    n_head: int = 8\n",
    "    n_embd: int = 768\n",
    "    dropout: float = 0.0\n",
    "    bias: bool = False\n",
    "    model_type: str = 'reflex'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "602f265f-39a2-4f75-94b2-17f2e0703948",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cuda.matmul.allow_tf32 = True # allow tf32 on matmul\n",
    "torch.backends.cudnn.allow_tf32 = True # allow tf32 on cudnn\n",
    "device_type = 'cuda' if 'cuda' in device else 'cpu' # for later use in torch.autocast\n",
    "ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]\n",
    "ctx = nullcontext() if device_type == 'cpu' else torch.amp.autocast(device_type=device_type, dtype=ptdtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cbf8ce45-be4c-4259-a8a2-e3c4281bd221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 81.11M\n"
     ]
    }
   ],
   "source": [
    "ckpt_path = os.path.join(out_dir, 'ckpt.pt')\n",
    "checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "gptconf = GPTConfig(**checkpoint['model_args'])\n",
    "model = GPT(gptconf)\n",
    "state_dict = checkpoint['model']\n",
    "unwanted_prefix = '_orig_mod.'\n",
    "for k,v in list(state_dict.items()):\n",
    "    if k.startswith(unwanted_prefix):\n",
    "        state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "model.to(device)\n",
    "if compile:\n",
    "    model = torch.compile(model) # requires PyTorch 2.0 (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b4b49c75-39e3-40ff-a117-cefcc4161c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No meta.pkl found, assuming GPT-2 encodings...\n"
     ]
    }
   ],
   "source": [
    "print(\"No meta.pkl found, assuming GPT-2 encodings...\")\n",
    "enc = tiktoken.get_encoding(\"gpt2\")\n",
    "encode = lambda s: enc.encode(s, allowed_special={\"<|endoftext|>\"})\n",
    "decode = lambda l: enc.decode(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "08156e90-123a-472f-af3a-62ee6786ec49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to meet a love of your life?”\n",
      "\n",
      "This is a matter we’ve created a new world. Here’s the whole thing, as we are here with an individual, a bit of an interesting amount of political pressure. The fact that the word “N” is not an actual thing is a good thing, but we can’t wait for it.\n",
      "\n",
      "The other thing is that they are a few blocks away. They are the same with everyone else.\n",
      "\n",
      "After many long years we went on to live a little bit more in the same apartment with a more reliable estimate than a bad story. This was like a problem, but for a moment this change was seen in a different way than the one that’s been called a “Soda.”\n",
      "\n",
      "Here’s one thing that was also the perfect answer, and unfortunately, we’ve had a lot of useful results, but the news has been going well.\n",
      "\n",
      "\"It was a good idea, I think, just a little bit of a joke. I started this with a story about a job that I could barely draw for, say, a bit, I think that was a matter of curiosity. If you work with a team, or a bad person, do you know, I wasn't doing that,\" he said, adding that he was the only person that showed up at that time.\n",
      "\n",
      "But with a similar conclusion, we’ve seen a lot of social changes, with all the other things we had before the interview was the same thing. Instead, I’ve seen a lot of great things to do. We had to be careful, put out there literally. We didn’t have a lot of good things, but we didn’t want to be fair, and on top of the job. This was a little bit, so it was a bit of a shame. Because we’ve got to take a lot of good communication in order to stay positive, rather than get rid of it.\n",
      "\n",
      "The thing is now an extra two years in the job, but it’s often never really a problem.\n",
      "\n",
      "We have seen a couple of people write about this, including a good one, and in fact, a few have known about the job, right? One in each of us has already been telling us the fact that’s all we have, and yet they don’t\n",
      "---------------\n",
      "How to meet a love of your life?\n",
      "\n",
      "We can change a lot of the time, at least we can remember and try to find another. But this might look like a possibility.<|endoftext|>Tantastic, or so, could be what some of us do. The biggest part of a human being is the high cost of cleaning up the subject. What happens in that particular event is the middle class, and we can all stay focused on the role of the person and others.\n",
      "\n",
      "In a recent interview with the Daily Beast, one of the first projects in a row on the web is the chance that the more important part of society is to keep people informed about the exact location of two things: “Pentagonia is a world that is very popular and fun to have.” An impressive thing about the idea of a future-overdue environment’s end-to-world perspective is the \"Racist\" version of an argument that is not going to be addressed. The only reason we know how to be sure is if it’s over.\n",
      "\n",
      "Here's the main point here: You’ll find a single member of one of your favorite books. With the help of a small number of people living under your roof would not be a major measure in the future. What is a direct result of the question mark, how the court is going to turn out. If you do it, you have to take some of the blame.\n",
      "\n",
      "So if you ask the best of the two major political events, or have been described in the past, or do you believe that if you are the dominant system of things, not only do you know the way (or do you have to figure out that you are going to get some good information into another year. If you are a fan-level man that doesn’t fit into your head, and it should be a matter of time before the end of the day. It is a real, fun thing.\n",
      "\n",
      "It’s important to note that you will see many people working on the project. This will be very easy for the whole task.\n",
      "\n",
      "This is an important challenge to any part of the world. It is to identify the same thing. I’m not alone, after all. The question is still on display and in the first instance, I’m a big group. I’m sure, I’m not surprised that this is not something that looks like a\n",
      "---------------\n",
      "How to meet a love of your life?\n",
      "\n",
      "You don't want to talk about the most important people of all day, and it happens to be quite a little less scary. So, what, you know, is not the only way to deal with that.\n",
      "\n",
      "To speak in an event that was done by the community, and I think it's a long game, but it's a good idea. That, so it is really something that was covered around the globe as you were talking about. The other day, when you have something to take away is the wrong kind of thing to actually need to be heard.\n",
      "\n",
      "I have a good place, for the moment, but what's getting changed is that it can be a part of this entire issue. That’s a lot more than a week as long as you are talking to me. First, the other choice is a small, easy-than-disclosure.\n",
      "\n",
      "There’s been a moment of silence. During the day, it was a very low-issue, so that was my friend who had to be nice to me. I didn’t have to go through a lot of things, and not like the rest of the world. Like most people, I know how to break the balance of power, not only from being as good a little bit of a deal. But there’s a big thing.\n",
      "\n",
      "I don’t think that’s a little bit like this: I get a bunch of different characters on the same page. And with that said, I think of a lot of those characters:\n",
      "\n",
      "Well, now it’s not easy to get a great deal of excitement, but it’s just a little bit like, I only recently started off with just a few different ways.\n",
      "\n",
      "But the most important thing is not to be honest with the other four.\n",
      "\n",
      "For many years I have been sitting in a company.\n",
      "\n",
      "The point of the fact is that the fact that the phone is a little different has been made even more positive than it really was. It’s part of how the picture is important. One way we know that we make a lot of stories. It’s an issue since the day when we were able to get into the camera and use our own network was a matter of time.\n",
      "\n",
      "And the big thing that’s been said before, is that the whole process is a bit more exciting\n",
      "---------------\n",
      "How to meet a love of your life?\n",
      "\n",
      "I do not, and they don’t have the same person, they have no way of connecting to me, I think I could play an important part of my life for years.\n",
      "\n",
      "I have an obligation to consider my interest. My first thought was to keep track of my own.\n",
      "\n",
      "A few things are not there.\n",
      "\n",
      "I am told to keep on the job. It is not a question of life.\n",
      "\n",
      "For now, I have been out of the way to this day and I am very proud of how I am about a man who has a long and long history of living that is now suffering for a long time. So I am very optimistic.\n",
      "\n",
      "When I was four years old, I've had an emotional impact on the status quo. And despite I am a huge fan of what I am told that I am at my house. I will be able to take an hour and a half. So this is not very much a fun gift, but if I have been with a good time and a great deal of time.\n",
      "\n",
      "If those who are doing my own thing will not turn into the next day, the second of all is a few bad things.\n",
      "\n",
      "\"The biggest question I have in mind is the number of people who are tired of the news. At the moment, they will pay more than I have ever done, and I think I have to deal with the next few things, and that's the biggest challenge I am going to make,\" said one reporter.\n",
      "\n",
      "\"The most obvious part of it is that we have a sense that the game is over,” said one of those people. “The video that was taken is not supposed to be for a short period. We are on the verge of another election, and we believe that the idea of just working for a job is not entirely fair.”\n",
      "\n",
      "The good news for me to pay a shot is the fact that I am a bit too low. I suspect that the idea of the American service is one of the best of times. As I have been so far, I am aware of it having a full-scale appeal to the internet. I am grateful for the fact that there is a very successful process of making a living as a result of the show.\n",
      "\n",
      "I think the most important thing I see in New York is that it is a sad idea to see the impact of the company that had a\n",
      "---------------\n",
      "How to meet a love of your life? Now, if that’s good,” says Yarnivale, and Norton of the West Bank.\n",
      "\n",
      "The story of his second choice is well-known within the American society, for a place where he says he has a hard time and is the single most dangerous. It’s a lot of people were told: a third of the three main problems with the book were the same. On the other hand, with a couple of decades of experience, one would have to do with the plan.\n",
      "\n",
      "While the current police say everything around a lot, the person who was interested in getting rid of their people was a great example. No big-city solution is made but a lot of us don’t know it, regardless of what’s there. I’ve done a bigger job than many other people. But no one’s telling me the kind of stuff that our team is talking about now is a great opportunity to learn and get us to know what we’re talking about. The amount of support we’re about is already starting to get in here.\n",
      "\n",
      "Some people, like those who’ve ever seen it, are happy to be in a very good position. If you have a little bit of a clue: it’s a good idea to get the full distance. I’d like to see a little bit of criticism from the media. I think about this, but I’d always wanted to see some kind of a better life, but it’s also a huge benefit with a lot of the same things I’ve been around for a while. One of the most important things about this interview …\n",
      "\n",
      "So it’s still a good idea to do a fairly simple, honest effort to find the next day. It’s also possible for the public to have a lot of people around the world, not just in time for the people who are already here. I could not hear a single one of the best players I’ve ever seen in the world. I’m excited that I didn’t know the answers. This is not just a decision we’re expecting.\n",
      "\n",
      "What’s your reaction to the conversation is that the only way we can see is a massive picture, although this is the same thing: every part of the press, in my heart would not be a\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "# encode the beginning of the prompt\n",
    "if start.startswith('FILE:'):\n",
    "    with open(start[5:], 'r', encoding='utf-8') as f:\n",
    "        start = f.read()\n",
    "start_ids = encode(start)\n",
    "x = (torch.tensor(start_ids, dtype=torch.long, device=device)[None, ...])\n",
    "\n",
    "# run generation\n",
    "with torch.no_grad():\n",
    "    with ctx:\n",
    "        for k in range(num_samples):\n",
    "            y = model.generate(x, max_new_tokens, temperature=temperature, top_k=top_k)\n",
    "            print(decode(y[0].tolist()))\n",
    "            print('---------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ba64cd-99d1-4213-941a-939b0eb48988",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
